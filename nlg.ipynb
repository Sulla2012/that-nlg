{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "narrative-version",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/r/rbond/jorlo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='tensorflow'\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import numpy\n",
    "import sys\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ed4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sorted-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_words(input):\n",
    "    # lowercase everything to standardize it\n",
    "    input = input.lower()\n",
    "\n",
    "    # instantiate the tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(input)\n",
    "\n",
    "    # if the created token isn't in the stop words, make it part of \"filtered\"\n",
    "    filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    return \" \".join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "thick-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../../texts/communist-manifesto.txt').read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wired-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_inputs = tokenize_words(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sitting-deployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 48620\n",
      "Total vocab: 37\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(processed_inputs)))\n",
    "char_to_num = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "input_len = len(processed_inputs)\n",
    "vocab_len = len(chars)\n",
    "print (\"Total number of characters:\", input_len)\n",
    "print (\"Total vocab:\", vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "apart-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "x_data = []\n",
    "y_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "disturbed-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through inputs, start at the beginning and go until we hit\n",
    "# the final character we can create a sequence out of\n",
    "for i in range(0, input_len - seq_length, 1):\n",
    "    # Define input and output sequences\n",
    "    # Input is the current character plus desired sequence length\n",
    "    in_seq = processed_inputs[i:i + seq_length]\n",
    "\n",
    "    # Out sequence is the initial character plus total sequence length\n",
    "    out_seq = processed_inputs[i + seq_length]\n",
    "\n",
    "    # We now convert list of characters to integers based on\n",
    "    # previously and add the values to our lists\n",
    "    x_data.append([char_to_num[char] for char in in_seq])\n",
    "    y_data.append(char_to_num[out_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "corresponding-depth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 48520\n"
     ]
    }
   ],
   "source": [
    "n_patterns = len(x_data)\n",
    "print (\"Total Patterns:\", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "controversial-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
    "X = X/float(vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "banned-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = utils.to_categorical(y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "apparent-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "funky-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"model_weights_saved.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "desired_callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "occupied-syndrome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48520 samples\n",
      "Epoch 1/40\n",
      "48128/48520 [============================>.] - ETA: 0s - loss: 2.9529\n",
      "Epoch 00001: loss improved from inf to 2.95219, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 15s 319us/sample - loss: 2.9522\n",
      "Epoch 2/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 2.9117\n",
      "Epoch 00002: loss improved from 2.95219 to 2.91141, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 10s 201us/sample - loss: 2.9114\n",
      "Epoch 3/40\n",
      "48128/48520 [============================>.] - ETA: 0s - loss: 2.9046\n",
      "Epoch 00003: loss improved from 2.91141 to 2.90474, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 9s 182us/sample - loss: 2.9047\n",
      "Epoch 4/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 2.9018\n",
      "Epoch 00004: loss improved from 2.90474 to 2.90176, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 154us/sample - loss: 2.9018\n",
      "Epoch 5/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 2.8986\n",
      "Epoch 00005: loss improved from 2.90176 to 2.89857, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 8s 156us/sample - loss: 2.8986\n",
      "Epoch 6/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 2.8988\n",
      "Epoch 00006: loss did not improve from 2.89857\n",
      "48520/48520 [==============================] - 7s 154us/sample - loss: 2.8987\n",
      "Epoch 7/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 2.8965\n",
      "Epoch 00007: loss improved from 2.89857 to 2.89651, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 8s 155us/sample - loss: 2.8965\n",
      "Epoch 8/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 2.8863\n",
      "Epoch 00008: loss improved from 2.89651 to 2.88610, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 154us/sample - loss: 2.8861\n",
      "Epoch 9/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 2.7302\n",
      "Epoch 00009: loss improved from 2.88610 to 2.73012, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 147us/sample - loss: 2.7301\n",
      "Epoch 10/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 2.6235\n",
      "Epoch 00010: loss improved from 2.73012 to 2.62342, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 150us/sample - loss: 2.6234\n",
      "Epoch 11/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 2.5092\n",
      "Epoch 00011: loss improved from 2.62342 to 2.50974, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 148us/sample - loss: 2.5097\n",
      "Epoch 12/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 2.4065\n",
      "Epoch 00012: loss improved from 2.50974 to 2.40612, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 152us/sample - loss: 2.4061\n",
      "Epoch 13/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 2.3239\n",
      "Epoch 00013: loss improved from 2.40612 to 2.32418, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 152us/sample - loss: 2.3242\n",
      "Epoch 14/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 2.2500\n",
      "Epoch 00014: loss improved from 2.32418 to 2.24982, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 154us/sample - loss: 2.2498\n",
      "Epoch 15/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 2.1800\n",
      "Epoch 00015: loss improved from 2.24982 to 2.18044, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 152us/sample - loss: 2.1804\n",
      "Epoch 16/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 2.1272\n",
      "Epoch 00016: loss improved from 2.18044 to 2.12721, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 152us/sample - loss: 2.1272\n",
      "Epoch 17/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 2.0755\n",
      "Epoch 00017: loss improved from 2.12721 to 2.07549, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 153us/sample - loss: 2.0755\n",
      "Epoch 18/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 2.0321\n",
      "Epoch 00018: loss improved from 2.07549 to 2.03215, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 151us/sample - loss: 2.0321\n",
      "Epoch 19/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.9894\n",
      "Epoch 00019: loss improved from 2.03215 to 1.98970, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 154us/sample - loss: 1.9897\n",
      "Epoch 20/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.9546\n",
      "Epoch 00020: loss improved from 1.98970 to 1.95444, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 8s 157us/sample - loss: 1.9544\n",
      "Epoch 21/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.9270\n",
      "Epoch 00021: loss improved from 1.95444 to 1.92715, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 9s 194us/sample - loss: 1.9271\n",
      "Epoch 22/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.8979\n",
      "Epoch 00022: loss improved from 1.92715 to 1.89753, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 10s 207us/sample - loss: 1.8975\n",
      "Epoch 23/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.8680\n",
      "Epoch 00023: loss improved from 1.89753 to 1.86823, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 10s 208us/sample - loss: 1.8682\n",
      "Epoch 24/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.8423\n",
      "Epoch 00024: loss improved from 1.86823 to 1.84254, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 10s 205us/sample - loss: 1.8425\n",
      "Epoch 25/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.8220\n",
      "Epoch 00025: loss improved from 1.84254 to 1.82193, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 9s 192us/sample - loss: 1.8219\n",
      "Epoch 26/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.7987\n",
      "Epoch 00026: loss improved from 1.82193 to 1.79850, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 9s 185us/sample - loss: 1.7985\n",
      "Epoch 27/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.7762\n",
      "Epoch 00027: loss improved from 1.79850 to 1.77578, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 8s 165us/sample - loss: 1.7758\n",
      "Epoch 28/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.7584\n",
      "Epoch 00028: loss improved from 1.77578 to 1.75830, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 148us/sample - loss: 1.7583\n",
      "Epoch 29/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.7429\n",
      "Epoch 00029: loss improved from 1.75830 to 1.74320, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 150us/sample - loss: 1.7432\n",
      "Epoch 30/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.7273\n",
      "Epoch 00030: loss improved from 1.74320 to 1.72720, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 151us/sample - loss: 1.7272\n",
      "Epoch 31/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.7041\n",
      "Epoch 00031: loss improved from 1.72720 to 1.70374, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 150us/sample - loss: 1.7037\n",
      "Epoch 32/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.6981\n",
      "Epoch 00032: loss improved from 1.70374 to 1.69810, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 8s 156us/sample - loss: 1.6981\n",
      "Epoch 33/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.6737\n",
      "Epoch 00033: loss improved from 1.69810 to 1.67382, saving model to model_weights_saved.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48520/48520 [==============================] - 8s 159us/sample - loss: 1.6738\n",
      "Epoch 34/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.6660\n",
      "Epoch 00034: loss improved from 1.67382 to 1.66652, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 154us/sample - loss: 1.6665\n",
      "Epoch 35/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.6484\n",
      "Epoch 00035: loss improved from 1.66652 to 1.64840, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 8s 155us/sample - loss: 1.6484\n",
      "Epoch 36/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.6422\n",
      "Epoch 00036: loss improved from 1.64840 to 1.64195, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 152us/sample - loss: 1.6419\n",
      "Epoch 37/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.6268\n",
      "Epoch 00037: loss improved from 1.64195 to 1.62646, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 153us/sample - loss: 1.6265\n",
      "Epoch 38/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.6092\n",
      "Epoch 00038: loss improved from 1.62646 to 1.60866, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 148us/sample - loss: 1.6087\n",
      "Epoch 39/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.5962\n",
      "Epoch 00039: loss improved from 1.60866 to 1.59601, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 154us/sample - loss: 1.5960\n",
      "Epoch 40/40\n",
      "48384/48520 [============================>.] - ETA: 0s - loss: 1.5905\n",
      "Epoch 00040: loss improved from 1.59601 to 1.59072, saving model to model_weights_saved.hdf5\n",
      "48520/48520 [==============================] - 7s 154us/sample - loss: 1.5907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffcb05321d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=40, batch_size=256, callbacks=desired_callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "generic-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"model_weights_saved.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "great-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_char = dict((i, c) for i, c in enumerate(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adjustable-collection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:\n",
      "\" lands climes place old local national seclusion self sufficiency intercourse every direction univers \"\n"
     ]
    }
   ],
   "source": [
    "start = numpy.random.randint(0, len(x_data) - 1)\n",
    "pattern = x_data[start]\n",
    "print(\"Random Seed:\")\n",
    "print(\"\\\"\", ''.join([num_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "republican-cruise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "al courgeois socialism communists proletariat proletariat proletariat proletariat proletariat proletariat proletariat proletariat proletariat proletariat proletariat proletariat proletariat proletariat proletariat proletariat proletariat proletariat proletariat proletariat proletariat proletariat p"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e375cbfe6f79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_to_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gpu-ml-clusters/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gpu-ml-clusters/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gpu-ml-clusters/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gpu-ml-clusters/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gpu-ml-clusters/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gpu-ml-clusters/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gpu-ml-clusters/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.conda/envs/gpu-ml-clusters/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gpu-ml-clusters/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gpu-ml-clusters/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gpu-ml-clusters/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.conda/envs/gpu-ml-clusters/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(vocab_len)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = num_to_char[index]\n",
    "\n",
    "    sys.stdout.write(result)\n",
    "\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-seven",
   "metadata": {},
   "source": [
    "# TF Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "worth-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8206a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b73ee96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "82e20328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                batch_input_shape=[batch_size,None]),\n",
    "        tf.keras.layers.GRU(rnn_units, return_sequences = True, stateful = True,\n",
    "                recurrent_initializer = 'glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "animated-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('../../texts/communist-manifesto.txt', 'rb').read().decode(encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "94243dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "81592219",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {unique:idx for idx, unique in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e41fe376",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_int = np.array([char2idx[char] for char in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4c2e0b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 50\n",
    "\n",
    "examples_per_epoch = len(text) // (seq_len + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3179a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ae4fd63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_len + 1, drop_remainder = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "80c1d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "899a4a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)\n",
    "\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "867195ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6194cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2c23f0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a8d80041",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'marx_{epoch}')\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_prefix, save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b740d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "eedeb961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 26 steps\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 3.7686\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 2.7863\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 2.4592\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 2.3054\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 2.2118\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 2.1250\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 2.0338\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 1.9290\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.8323\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 1.7411\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.6608\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 1.5856\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.5137\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.4491\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 1.3845\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.3263\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.2725\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 1.2205\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 1.1737\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.1214\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 1.0714\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 1.0246\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.9771\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.9314\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.8802\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.8315\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.7934\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.7444\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.7059\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.6660\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.6276\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.5986\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.5611\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.5313\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.5088\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.4790\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.4570\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.4359\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.4254\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.4095\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.3945\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.3798\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.3720\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.3612\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.3556\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.3483\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.3430\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.3358\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.3247\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.3185\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.3153\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.3104\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.3085\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.3014\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2991\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2951\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2900\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2883\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.2848\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2810\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.2763\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2736\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2697\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2714\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2670\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.2619\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2637\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.2592\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.2579\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.2585\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2556\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2545\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.2538\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.2503\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.2486\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.2447\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.2431\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2421\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2443\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2411\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2399\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.2389\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2390\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2357\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2328\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2337\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2318\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2322\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2301\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.2306\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2284\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2318\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2287\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2236\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2270\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2215\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2221\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2237\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2202\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 25ms/step - loss: 0.2231\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs = EPOCHS, callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "f3ee214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_model = build_model(vocab_size, embedding_dim, rnn_units, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "64c8792b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ffb1c36ac90>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generative_model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b2b6e806",
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_model.build(tf.TensorShape([1,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "bacb9151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_text(model, start_string):\n",
    "    num_gen = 1000\n",
    "    start_string = 'Workers'\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    text_generated = []\n",
    "    temperature = 1.0\n",
    "    model.reset_states()\n",
    "    \n",
    "    for i in range(num_gen):\n",
    "        predictions = generative_model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples = 1)[-1,0].numpy()\n",
    "        \n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "    while idx2char[predicted_id] != '.':\n",
    "        predictions = generative_model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples = 1)[-1,0].numpy()\n",
    "        \n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9475474c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Workersan \\nexpenditure of labour, in converting carbons; modity, therefore, varies directly as the quantity, liked,\\nserfs; in almost all of these classes, against the more advanced opposition parties, ss the bourgeoisie forged the weapons that bring\\nd of speech.\\n\\nFree trade: for the benefit of the working class; suenth century, and since then constantly,\\ncompetition, to all the fluciations, on pain of extinction, to\\nalonither words, the more modern industry has established the world-market, for the productioncharacter of the sy, the small manufacturer, the\\nshopkeeper, the artis earnest.\\n\\nBy thiselations, and the old society, or\\nto cramping the manufacturer\\nhimes of different quantities, and consequently into a population from the idiocy of rural\\nlife.  Just as, therefore, at\\nan earlier ones. Aly felt conscious of has individuality,\\nwhile the living person is the necessary offspring of their\\nown form of society we are about to consider, they are a small expenditure of labour, in conver in Germany they fight with the bourgeoisie whenever its practical arsiblishen restoractions\\nof emancipation, thas y,\\n\\nIn doping, the more, by the action of Modern Industry, all that which determines the magnis class struggle and to reconcile the class antagonisms.'"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_text(generative_model, 'Workers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b2515925",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6cf6937e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[1]], dtype=int32)>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9443f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-ml-clusters",
   "language": "python",
   "name": "gpu-ml-clusters"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
